{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38ad738-88f5-43f4-98d4-57e2cd26e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from datetime import date, timedelta\n",
    "from scipy.sparse import vstack\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PDSum_components import *\n",
    "from PDSum_evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae594181-f6bd-4d7f-af6c-62e8eab1a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_NUM = 0\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6147b8dc",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3d3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WCEP\n",
    "df_org = pd.read_json(\"datasets/WCEP_EMDS_articles.json\")\n",
    "stories = pd.read_json(\"datasets/WCEP_EMDS_reference_summaries.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a452c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#W2E\n",
    "df_org = pd.read_json(\"datasets/W2E_EMDS_articles.json\")\n",
    "stories = pd.read_json(\"datasets/W2E_EMDS_reference_summaries.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92979b3",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0114ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = df_org # df_org[:100] for the first 100 articles for test\n",
    "target_df, masked_tensors, masks, all_vocab = initialize(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58dfaeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embds = torch.div(masked_tensors.sum(1),(1-masks).sum(1).reshape(-1,1)).cpu().detach().numpy()\n",
    "\n",
    "df_org['mean_embd'] = list(mean_embds)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1,2), tokenizer=lambda x: x, lowercase=False, norm=None)\n",
    "tfidf_vectorizer.fit_transform([sum(k, []) for k in df_org['sentence_tokens']])\n",
    "all_vocab = tfidf_vectorizer.get_feature_names()\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer=lambda x: x, ngram_range = (1,2), vocabulary = list(all_vocab), lowercase=False)\n",
    "df_org['sentence_TFs'] = [count_vectorizer.transform(y) for y in df_org['sentence_tokens'].values]\n",
    "df_org['article_TF'] = [sum(a) for a in df_org['sentence_TFs'].values]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0239e119",
   "metadata": {},
   "source": [
    "# Setting Hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e82a725",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Default'# Default or Custom - Default: summaries are returned at every unique date (e.g., WCEP) or Custom: at every true summary date (e.g., W2E)\n ",
    "max_sentences = 1\n",
    "max_tokens = 40\n",
    "\n",
    "batch = 64\n",
    "epoch= 5\n",
    "temp = 0.2\n",
    "\n",
    "D_in = 1024\n",
    "D_hidden = 1024\n",
    "head = 2\n",
    "dropout = 0\n",
    "lr = 1e-5\n",
    "N = 10\n",
    "distill_ratio = 0.5\n",
    "\n",
    "model = Model(D_in, D_hidden, head, dropout).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46e81e1",
   "metadata": {},
   "source": [
    "# Simulating EMDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa8d3380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925a849f61ec4e7990bd60972f2c0714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/235 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Queries = list(target_df.Query.unique())\n",
    "tuned_summary = pd.DataFrame(index=Queries)\n",
    "\n",
    "theme_dic = {}\n",
    "weights_dic = {}\n",
    "\n",
    "losses = []\n",
    "weights = {}\n",
    "accum_weights = {}\n",
    "centers = {}\n",
    "accum_centers = {}\n",
    "accum_cluster_topN_indices = {}\n",
    "accum_cluster_topN_scores = {}\n",
    "prev_summaries = {}\n",
    "to_drop_indices = []\n",
    "target_window_indices = []\n",
    "WE2_concurrent_queries_df = pd.DataFrame(columns = ['queries'])\n",
    "\n",
    "for date in tqdm(target_df.date.unique()):\n",
    "   \n",
    "    ### Get the current context ###\n",
    "    if dataset == 'Default': #WCEP\n", 
    "        ### Retrieve target window (by each date) ###\n",
    "        target_window_indices = target_df[target_df.date==date].index\n",
    "        target_window = target_df.loc[target_window_indices]\n",
    "        target_window_queries = list(target_window['Query'].unique())\n",
    "        summary_basis_queries = target_window_queries\n",
    "    elif dataset == 'Custom': #W2E\n", 
    "        ### Retrieve target window (by each true summary)###\n",
    "        target_window_indices = list(set(target_window_indices) - set(to_drop_indices))\n",
    "        target_window_indices = target_window_indices + list(target_df[target_df.date==date].index)\n",
    "        target_window = target_df.loc[target_window_indices]\n",
    "        target_window_queries = list(target_window['Query'].unique())\n",
    "        \n",
    "        curr_stories = stories[stories.date==date].Query.unique()\n",
    "        summary_basis_queries = curr_stories\n",
    "        if len(curr_stories) < 1:\n",
    "            to_drop_indices = []\n",
    "            continue\n",
    "        to_drop_indices = target_window[target_window.Query.isin(curr_stories)].index\n",
    "        WE2_concurrent_queries_df.loc[date,'queries'] = target_window_queries\n",
    "        if len(target_window[target_window.Query.isin(summary_basis_queries)]) < 1: continue\n",
    "    \n",
    "    ### Get set phrases ###\n",
    "    cluster_topN_indices, cluster_topN_scores, cluster_topN_words = get_cluster_theme(all_vocab, target_window, N)\n",
    "    theme_dic[date] = (cluster_topN_indices, cluster_topN_scores, cluster_topN_words)\n",
    "    weights = {}\n",
    "    for query in target_window.Query.unique():\n",
    "        weights_raw = np.array(vstack([x[0, cluster_topN_indices[query]] for x in target_window[target_window.Query==query].article_TF.values]).multiply(cluster_topN_scores[query]).sum(1)).squeeze(1)\n",
    "        weights[query] = weights_raw/np.sum(weights_raw)\n",
    "    weights_dic[date] = weights\n",
    "\n",
    "\n",
    "    ### Set previous set phrases ###\n",
    "    for query in summary_basis_queries:\n",
    "        if query not in accum_cluster_topN_indices:\n",
    "            accum_cluster_topN_indices[query] =  cluster_topN_indices[query]\n",
    "            accum_cluster_topN_scores[query] = cluster_topN_scores[query]\n",
    "        else:\n",
    "            accum_cluster_topN_indices[query] = np.append(accum_cluster_topN_indices[query] , cluster_topN_indices[query])\n",
    "            accum_cluster_topN_scores[query] = np.append(accum_cluster_topN_scores[query] , cluster_topN_scores[query])\n",
    "    \n",
    "\n",
    "    ### Initialize set prototypes ###\n",
    "    for query in target_window_queries:\n",
    "        weights = weights_dic[date]\n",
    "        ## Initialize set prototype to mean embedding + set phrases ##\n",
    "        centers[query] = np.sum(target_window[target_window.Query==query].mean_embd.values * weights[query]) \n",
    "        \n",
    "        ## Initialize set prototype to tuned embedding + accum set phrases ##\n",
    "        if query in summary_basis_queries:\n",
    "            model.eval()\n",
    "            query_idices = target_window[target_window['Query']==query].index \n",
    "            outputs = model(masked_tensors[query_idices], masks[query_idices])\n",
    "            target_window.loc[query_idices, 'tuned_embd'] = pd.Series(list(outputs[0].squeeze(1).cpu().detach().numpy()), index=query_idices) \n",
    "        \n",
    "            accum_weights_raw = vstack(target_window[target_window.Query==query].article_TF.values)[:,accum_cluster_topN_indices[query]].multiply(accum_cluster_topN_scores[query]).sum(1).ravel().tolist()[0]\n",
    "            accum_weights[query] = accum_weights_raw/np.sum(accum_weights_raw)\n",
    "            accum_centers[query] = np.sum(target_window[target_window.Query==query].tuned_embd.values * accum_weights[query]) \n",
    "        else:\n",
    "            accum_centers[query] = centers[query]\n",
    "\n",
    "        \n",
    "    \n",
    "    ### Train a model ###\n",
    "    num_itr = int(len(target_window)/batch)+1\n",
    "    for e in range(epoch):\n",
    "        ## Model training ##\n",
    "        target_class_embds = torch.tensor(np.array([centers[q] * (1-distill_ratio) + distill_ratio *  accum_centers[q] for q in target_window.Query.unique()])).cuda()\n",
    "        \n",
    "        for itr in range(num_itr):\n",
    "            model.train()\n",
    "            samples = np.random.choice(target_window.index, batch) #window.index            \n",
    "            class_indices = [target_window_queries.index(q) for q in target_window.loc[samples,'Query']]\n",
    "            sample_outputs = model(masked_tensors[samples], masks[samples])[0].squeeze(1)\n",
    "            loss = get_loss(sample_outputs, class_indices, target_class_embds, temp)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        losses.append(loss)\n",
    "\n",
    "        ## Center update ##\n",
    "        model.eval()\n",
    "        for query in summary_basis_queries:\n",
    "            query_idices = target_window[target_window['Query']==query].index \n",
    "            outputs = model(masked_tensors[query_idices], masks[query_idices])\n",
    "            target_window.loc[query_idices, 'tuned_embd'] = pd.Series(list(outputs[0].squeeze(1).cpu().detach().numpy()), index=query_idices) \n",
    "            accum_centers[query] = np.sum(target_window[target_window.Query==query].tuned_embd.values * accum_weights[query]) \n",
    "\n",
    "    ### Summarize sets ###\n",
    "    ## Sentence score computation ##\n",
    "    tuned_summaries = []\n",
    "\n",
    "    for query in summary_basis_queries:\n",
    "        query_window = target_window[target_window.Query==query]\n",
    "        if len(query_window) < 1: continue\n",
    "        outputs = model(masked_tensors[query_window.index], masks[query_window.index])\n",
    "        sentences_ap_weights = outputs[2].cpu().detach().numpy().squeeze(2)\n",
    "        sentences_tuned_embds = outputs[3].cpu().detach().numpy()\n",
    "\n",
    "        docs_sims = cosine_similarity([centers[query]], np.array(list(query_window.tuned_embd.values)))[0]\n",
    "        doc_phrase_scores_raw = [x[:50, cluster_topN_indices[query]].multiply(cluster_topN_scores[query]) for x in query_window.sentence_TFs.values]\n",
    "        doc_phrase_scores_sum = vstack(doc_phrase_scores_raw).sum()\n",
    "        doc_phrase_scores = [np.array(x.sum(1)/doc_phrase_scores_sum).ravel() for x in doc_phrase_scores_raw]\n",
    "\n",
    "        accum_doc_sims = cosine_similarity([accum_centers[query]], np.array(list(query_window.tuned_embd.values)))[0]\n",
    "        accum_doc_phrase_scores_raw = [x[:50, accum_cluster_topN_indices[query]].multiply(accum_cluster_topN_scores[query]) for x in query_window.sentence_TFs.values]\n",
    "        accum_sentence_phrase_scores_sum = vstack(accum_doc_phrase_scores_raw).sum()\n",
    "        accum_doc_phrase_scores = [np.array(x.sum(1)/accum_sentence_phrase_scores_sum).ravel() for x in accum_doc_phrase_scores_raw]\n",
    "        \n",
    "        summary_scores = []\n",
    "        for doc_id in range(len(query_window)):\n",
    "            doc_score = np.exp(docs_sims[doc_id]) * (1-distill_ratio) + distill_ratio * np.exp(accum_doc_sims[doc_id])\n",
    "            for sen_id in range(min(50,query_window.iloc[doc_id].sentence_counts)):\n",
    "                sentence_phrase_score = doc_phrase_scores[doc_id][sen_id] * (1-distill_ratio) + distill_ratio * accum_doc_phrase_scores[doc_id][sen_id]\n",
    "                composite_score = doc_score  * sentences_ap_weights[doc_id][sen_id]  * sentence_phrase_score  \n",
    "                summary_scores.append((composite_score, query_window.iloc[doc_id].sentences[sen_id], sentences_tuned_embds[doc_id][sen_id]))\n",
    "        \n",
    "        ## Pick top sentences ##\n",
    "        summary_scores.sort(reverse=True, key=lambda e:e[0])\n",
    "        \n",
    "        all_tokens = []\n",
    "        all_sentences = []\n",
    "        all_sentences_embds = []\n",
    "        while len(all_sentences) < max_sentences: \n",
    "            (score, sentence, tuned_embd) =  summary_scores.pop(0)\n",
    "            all_sentences.append(sentence.replace(\"\\n\",\" \"))\n",
    "            all_sentences_embds.append(tuned_embd)\n",
    "        summary = ' '.join(all_sentences)\n",
    "        tuned_summaries.append(summary)\n",
    "        \n",
    "        if query not in prev_summaries:\n",
    "            prev_summaries[query] = all_sentences_embds\n",
    "        else:\n",
    "            prev_summaries[query] = prev_summaries[query] + all_sentences_embds\n",
    "    \n",
    "    tuned_summary[str(date)[:10]] = pd.Series(tuned_summaries, index = summary_basis_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ed0d6",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2b0b2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2019-01-01</th>\n",
       "      <th>2019-01-02</th>\n",
       "      <th>2019-01-03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68967</th>\n",
       "      <td>• Watch New Horizons probe ring in the New Ye...</td>\n",
       "      <td>Scientists are already learning more about Ult...</td>\n",
       "      <td>Around 10 hours after reaching the icy world o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68982</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Robow's arrest has been seen as a high-profile...</td>\n",
       "      <td>Somalia’s U.N. Ambassador Abukar Dahir Osman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68968</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Cook said Apple has lowered its revenue guidan...</td>\n",
       "      <td>Apple stocks have tumbled, after the company r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              2019-01-01  \\\n",
       "68967   • Watch New Horizons probe ring in the New Ye...   \n",
       "68982                                                NaN   \n",
       "68968                                                NaN   \n",
       "\n",
       "                                              2019-01-02  \\\n",
       "68967  Scientists are already learning more about Ult...   \n",
       "68982  Robow's arrest has been seen as a high-profile...   \n",
       "68968  Cook said Apple has lowered its revenue guidan...   \n",
       "\n",
       "                                              2019-01-03  \n",
       "68967  Around 10 hours after reaching the icy world o...  \n",
       "68982    Somalia’s U.N. Ambassador Abukar Dahir Osman...  \n",
       "68968  Apple stocks have tumbled, after the company r...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_summary[tuned_summary.columns[:3]].head(3) # Example output summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afc5b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_summary = get_tokenized_summary(tuned_summary)\n",
    "t_reference_summaries = []\n",
    "for (idx, row) in stories.iterrows():\n",
    "        t_reference_summaries.append(get_tokens(row['summary']))\n",
    "stories['tokenized_summary'] = t_reference_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9c5787e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_relevance_df = get_daily_score_df(t_summary, stories, 'ROUGE', 'L', WE2_concurrent_queries_df)\n",
    "relevance_score = np.round(np.mean(sum([list(output_relevance_df[date].dropna().values) for date in output_relevance_df], []),0)*100, 2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7512571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_novel_df, output_overlap_df, novel_ratio_df = get_novel_overlap_score_df(t_summary, stories, 'ROUGE', 'L')\n",
    "novelty_score = np.round(np.mean(sum([list(output_novel_df[date].dropna().values) for date in output_novel_df], []),0)*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cf32f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_contrast_df = get_daily_contrast_df(t_summary, stories, 'ROUGE', 'L', WE2_concurrent_queries_df)\n",
    "contrast_score = [100-x for x in np.round(np.mean(sum([sum(list(output_contrast_df[date].dropna().values), []) for date in output_contrast_df.columns],[]),0)*100,2)]\n",
    "distinctive_score = [np.round(x,2) for x in np.divide(contrast_score,(100-relevance_score))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d11119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22.4  23.41 21.17] [16.15 12.43 12.57] [1.29, 1.31, 1.27]\n"
     ]
    }
   ],
   "source": [
    "print(relevance_score, novelty_score, distinctive_score) #Precision, Recall, F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0612e2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dfa6e14e7404ef35cbde69cd8c2d952722f79e9799637b9afecd18e8686c957"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
